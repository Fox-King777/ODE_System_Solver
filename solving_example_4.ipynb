{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential Equation\n",
    "\n",
    "$\\frac{\\mathrm{d}\\Psi_1}{\\mathrm{d}x} = cos(x) + \\Psi_1^2 + \\Psi_2 - (1 + x^2 + sin^2(x)),$\n",
    "\n",
    "$\\frac{\\mathrm{d}\\Psi_2}{\\mathrm{d}x} = 2x - (1 - x^2)sin(x) + \\Psi_1\\Psi_2,$\n",
    "\n",
    "$\\Psi_1(0) = 0, \\Psi_2(0) = 1, x \\in [0, 3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable\n",
    "import autograd.numpy as np\n",
    "from autograd import grad, elementwise_grad\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSI_0 = np.array([0, 1])\n",
    "\n",
    "def derivative(x, psi) -> np.ndarray:\n",
    "    \"\"\"Example #4 derivative.\n",
    "    Args:\n",
    "        x: The input vector\n",
    "        psi: The function vector\n",
    "\n",
    "    Returns:\n",
    "        Value of psi's partial derivatives at x.\n",
    "    \"\"\"\n",
    "    psi_1_dot = np.cos(x) + psi[0]**2 + psi[1] - (1 + x**2 + np.sin(x)**2)\n",
    "    psi_2_dot = 2 * x - (1 - x**2) * np.sin(x) + psi[0] * psi[1] \n",
    "    return np.array([psi_1_dot, psi_2_dot])\n",
    "\n",
    "def analytical_solution(x):\n",
    "    \"\"\"Analytical solution to example #4.\n",
    "    Args:\n",
    "        x: The input vector\n",
    "\n",
    "    Returns:\n",
    "        Value of psi at x.\n",
    "    \"\"\"\n",
    "    psi_1 = np.sin(x)\n",
    "    psi_2 = 1 + x**2\n",
    "\n",
    "    return np.array([psi_1, psi_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](NN.png \"Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"A neural network class for solving ODEs. Can be combine with other neural networks to solve system of ODEs.\n",
    "        Attributes:\n",
    "            init_condition (float): Initial condition for the target function.\n",
    "            derivative (Callable): Function that calculates the target derivative of the neural network.\n",
    "            input_size (int): Size of the input layer.\n",
    "            hidden_sizes (np.array): Array of integers representing the sizes of the hidden layers.\n",
    "            output_size (int): Size of the output layer.\n",
    "            activation_fns (List[Callable]): List of activation functions for each layer.\n",
    "            weights (List[np.array]): List of weights and biases for each layer.\n",
    "\n",
    "        Methods:\n",
    "            init_weights(): Initializes the weights and biases of the neural network.\n",
    "            forward(t: np.array, weights: List[np.array]) -> np.array: Makes a forward pass through the neural network.\n",
    "            trial_solution(t: np.array, weights: List[np.array]) -> np.ndarray: Calculates the trial solution.\n",
    "            elementwise_trial_solution(t: np.array, weights: List[np.array]) -> np.ndarray: Calculates the trial solution elementwise.\n",
    "            trial_grad(t: np.array, weights: List[np.array]) -> np.array: Calculates the gradient of the trial solution with respect to t.\n",
    "    \"\"\"\n",
    "    def __init__(self, init_condition: np.array, derivative: Callable, input_size: int, hidden_sizes: np.array, output_size: int, activation_fns: List[Callable]):\n",
    "        self.init_condition = init_condition\n",
    "        self.derivative = derivative\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.activation_fns = activation_fns\n",
    "        self.weights = [None] * (hidden_sizes.shape[0] + 1) # +1 for the output\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\" Initializes the weights and biases of the neural network \n",
    "        Args:\n",
    "            None\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # hidden weights and biases\n",
    "        self.weights[0] = np.random.randn(self.hidden_sizes[0], self.input_size + 1) # +1 for the bias\n",
    "        for i in range(1, self.hidden_sizes.shape[0]):\n",
    "            self.weights[i] = np.random.randn(self.hidden_sizes[i], self.hidden_sizes[i - 1] + 1) # +1 for the bias\n",
    "\n",
    "        # output weights and biases\n",
    "        self.weights[-1] = np.random.randn(self.output_size, self.hidden_sizes[-1] + 1) # +1 for the bias\n",
    "\n",
    "    def forward(self, t: np.array, weights: List[np.array]) -> np.array:\n",
    "        \"\"\"Makes a forward pass through the neural network.\n",
    "\n",
    "        Args:\n",
    "            t: The t vector\n",
    "            weights: The weights and biases of the neural network\n",
    "        \n",
    "        Returns:\n",
    "            A NumPy array of the output of the neural network of dim(self.output_size, len(t)).\n",
    "        \"\"\"\n",
    "        num_layers = len(weights)\n",
    "        # row matrix\n",
    "        t = t.reshape(-1, t.size)\n",
    "\n",
    "        z = None\n",
    "        a = t\n",
    "        for i in range(num_layers):\n",
    "            z = np.matmul(weights[i], np.concatenate((np.ones((1, t.size)), a), axis = 0))\n",
    "            a = self.activation_fns[i](z)\n",
    "        return z\n",
    "\n",
    "    def trial_solution(self, t: np.array, weights: List[np.array]) -> np.ndarray:\n",
    "        \"\"\"Calculates the trial solution of the system of ODEs.\n",
    "        \n",
    "        Args:\n",
    "            t: The input vector\n",
    "            weights: The weights and biases of the neural network\n",
    "        \n",
    "        Returns:\n",
    "            A NumPy array of the trial solution of the system of ODEs\n",
    "            dimension (len(t),)\n",
    "        \"\"\"\n",
    "        fp = self.forward(t, weights).reshape(t.size)\n",
    "        return self.init_condition + t * fp\n",
    "\n",
    "    def trial_grad(self, t: np.array, weights: List[np.array]) -> np.array:\n",
    "        \"\"\"Calculates the gradient of the trial solution of the Lorentz System.\n",
    "        \n",
    "        Args:\n",
    "            t: The input vector\n",
    "            weights: The weights and biases of the neural network\n",
    "        \n",
    "        Returns:\n",
    "            A NumPy array of the gradient of the trial solution of the Lorentz System with \n",
    "            dimension (len(t),)\n",
    "        \"\"\"\n",
    "        return elementwise_grad(self.trial_solution, 0)(t, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_function(t: np.array, neural_networks: List[NeuralNetwork], weights_list: List[List[np.array]]) -> List[float]:\n",
    "    \"\"\"Calculates the mean squared error a list of neural network.\n",
    "\n",
    "    Args:\n",
    "        t: The input vector\n",
    "        neural_networks: A list of neural networks\n",
    "\n",
    "    Returns:\n",
    "        Mean squared error value\n",
    "    \"\"\"\n",
    "    loss = [None] * len(neural_networks)\n",
    "    trial_sol = np.array([neural_networks[i].trial_solution(t, weights_list[i]) for i in range(len(neural_networks))])\n",
    "    \n",
    "    for i in range(len(neural_networks)):\n",
    "        grad_star = neural_networks[i].derivative(t, trial_sol)\n",
    "        grad = neural_networks[i].trial_grad(t, weights_list[i])\n",
    "        error = grad_star - grad\n",
    "        loss[i] = np.linalg.norm(error, 'fro') / np.sqrt(np.size(error))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def elementwise_loss_function(t: np.array, neural_networks: List[NeuralNetwork], weights_list, index) -> float:\n",
    "    return mse_loss_function(t, neural_networks, weights_list)[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(t: np.array, neural_networks: List[NeuralNetwork], num_iter: int, learn_rate: float):\n",
    "    \"\"\"Runs gradient descent for a given number of iterations\n",
    "\n",
    "    Args:\n",
    "        t: The input vector\n",
    "        num_iter: The number of iterations\n",
    "        learn_rate: The learning rate\n",
    "    \n",
    "    Returns:\n",
    "        neural_networks: A list of neural networks after gradient descent\n",
    "    \"\"\"\n",
    "    loss_grad_function = grad(elementwise_loss_function, 2)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        weights_list = [neural_networks[j].weights for j in range(len(neural_networks))]\n",
    "        print_loss(t, neural_networks, weights_list, i)\n",
    "\n",
    "        for j in range(len(neural_networks)):\n",
    "            loss_grad = loss_grad_function(t, neural_networks, weights_list, j)\n",
    "            \n",
    "            for k in range(len(neural_networks[j].weights)):\n",
    "                neural_networks[j].weights[k] = neural_networks[j].weights[k] - learn_rate * loss_grad[j][k]\n",
    "\n",
    "    return neural_networks\n",
    "\n",
    "def adam(t, neural_networks, num_iters=10000, step_size=0.001, b1=0.9, b2=0.999, eps=10**-8):\n",
    "    loss_grad_function = grad(elementwise_loss_function, 2)\n",
    "\n",
    "    m = [[np.zeros_like(neural_networks[i].weights[j]) for j in range(len(neural_networks[0].weights))] for i in range(len(neural_networks))]\n",
    "    v = [[np.zeros_like(neural_networks[i].weights[j]) for j in range(len(neural_networks[0].weights))] for i in range(len(neural_networks))]\n",
    "\n",
    "    mhat = [[None] * len(neural_networks[i].weights) for i in range(len(neural_networks))]\n",
    "    vhat = [[None] * len(neural_networks[i].weights) for i in range(len(neural_networks))]\n",
    "\n",
    "    prev_loss = 0\n",
    "    for i in range(num_iters):\n",
    "        weights_list = [neural_networks[j].weights for j in range(len(neural_networks))]\n",
    "        prev_loss = print_loss(t, neural_networks, weights_list, i, prev_loss)\n",
    "\n",
    "        for j in range(len(neural_networks)):\n",
    "            g = loss_grad_function(t, neural_networks, weights_list, j)\n",
    "            \n",
    "            for k in range(len(neural_networks[j].weights)):\n",
    "                m[j][k] = (1 - b1) * g[j][k]      + b1 * m[j][k]  # First  moment estimate.\n",
    "                v[j][k] = (1 - b2) * (g[j][k]**2) + b2 * v[j][k]  # Second moment estimate.\n",
    "                mhat[j][k] = m[j][k] / (1 - b1**(i + 1))    # Bias correction.\n",
    "                vhat[j][k] = v[j][k] / (1 - b2**(i + 1)) \n",
    "                neural_networks[j].weights[k] = neural_networks[j].weights[k] - step_size * mhat[j][k]/(np.sqrt(vhat[j][k]) + eps)\n",
    "    \n",
    "    return neural_networks\n",
    "\n",
    "def print_loss(t: np.array, neural_networks: List[NeuralNetwork], weights_list: List[List[np.array]], iter: int, prev_loss):\n",
    "    \"\"\"Prints the iteration number and loss of the neural networks.\n",
    "\n",
    "    Args:\n",
    "        t: The input vector\n",
    "        neural_networks: A list of neural networks\n",
    "        weights_list: The weights and biases of the neural networks\n",
    "    \n",
    "    Returns:\n",
    "        loss: The loss of the neural networks\n",
    "    \"\"\"\n",
    "    loss = mse_loss_function(t, neural_networks, weights_list)\n",
    "\n",
    "    print(\"\\033[38;5;189m\" + \"Iteration: \", iter)\n",
    "    print(\"\\033[38;5;210m\", loss)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;189mIteration:  0\n",
      "\u001b[38;5;210m [8.944842388448738, 5.785298501882782]\n",
      "\u001b[38;5;189mIteration:  1\n",
      "\u001b[38;5;210m [8.892904130478707, 5.775468686011619]\n",
      "\u001b[38;5;189mIteration:  2\n",
      "\u001b[38;5;210m [8.842453377951486, 5.767841961964772]\n",
      "\u001b[38;5;189mIteration:  3\n",
      "\u001b[38;5;210m [8.793516559336704, 5.762376560093642]\n",
      "\u001b[38;5;189mIteration:  4\n",
      "\u001b[38;5;210m [8.746116057989939, 5.759020320984328]\n",
      "\u001b[38;5;189mIteration:  5\n",
      "\u001b[38;5;210m [8.700269817909902, 5.7577103997652195]\n",
      "\u001b[38;5;189mIteration:  6\n",
      "\u001b[38;5;210m [8.655990947640657, 5.758373009942]\n",
      "\u001b[38;5;189mIteration:  7\n",
      "\u001b[38;5;210m [8.613287325874913, 5.760923254398579]\n",
      "\u001b[38;5;189mIteration:  8\n",
      "\u001b[38;5;210m [8.572161222098286, 5.765265152161698]\n",
      "\u001b[38;5;189mIteration:  9\n",
      "\u001b[38;5;210m [8.532608965729487, 5.771292052317134]\n",
      "\u001b[38;5;189mIteration:  10\n",
      "\u001b[38;5;210m [8.494620724695878, 5.77888766948555]\n",
      "\u001b[38;5;189mIteration:  11\n",
      "\u001b[38;5;210m [8.458180468235994, 5.787927853879571]\n",
      "\u001b[38;5;189mIteration:  12\n",
      "\u001b[38;5;210m [8.423266153876044, 5.79828285676154]\n",
      "\u001b[38;5;189mIteration:  13\n",
      "\u001b[38;5;210m [8.389850091066092, 5.80981948771325]\n",
      "\u001b[38;5;189mIteration:  14\n",
      "\u001b[38;5;210m [8.357899361991448, 5.82240259687302]\n",
      "\u001b[38;5;189mIteration:  15\n",
      "\u001b[38;5;210m [8.327376196971734, 5.835895789147604]\n",
      "\u001b[38;5;189mIteration:  16\n",
      "\u001b[38;5;210m [8.298238280751812, 5.850161700670323]\n",
      "\u001b[38;5;189mIteration:  17\n",
      "\u001b[38;5;210m [8.270439022732138, 5.865062208012107]\n",
      "\u001b[38;5;189mIteration:  18\n",
      "\u001b[38;5;210m [8.243927830962072, 5.880458760526835]\n",
      "\u001b[38;5;189mIteration:  19\n",
      "\u001b[38;5;210m [8.218650415390941, 5.896212881520674]\n",
      "\u001b[38;5;189mIteration:  20\n",
      "\u001b[38;5;210m [8.194549134497317, 5.9121868312466965]\n",
      "\u001b[38;5;189mIteration:  21\n",
      "\u001b[38;5;210m [8.17156339310357, 5.9282444111996595]\n",
      "\u001b[38;5;189mIteration:  22\n",
      "\u001b[38;5;210m [8.149630093681292, 5.944251879065911]\n",
      "\u001b[38;5;189mIteration:  23\n",
      "\u001b[38;5;210m [8.128684137608035, 5.960078934033915]\n",
      "\u001b[38;5;189mIteration:  24\n",
      "\u001b[38;5;210m [8.1086589676976, 5.975599727853557]\n",
      "\u001b[38;5;189mIteration:  25\n",
      "\u001b[38;5;210m [8.089487139746577, 5.990693858804179]\n",
      "\u001b[38;5;189mIteration:  26\n",
      "\u001b[38;5;210m [8.071100908897304, 6.005247311316726]\n",
      "\u001b[38;5;189mIteration:  27\n",
      "\u001b[38;5;210m [8.053432816003921, 6.01915331106793]\n",
      "\u001b[38;5;189mIteration:  28\n",
      "\u001b[38;5;210m [8.036416259564477, 6.03231307259307]\n",
      "\u001b[38;5;189mIteration:  29\n",
      "\u001b[38;5;210m [8.01998603988646, 6.0446364232878524]\n",
      "\u001b[38;5;189mIteration:  30\n",
      "\u001b[38;5;210m [8.004078863784049, 6.056042293868639]\n",
      "\u001b[38;5;189mIteration:  31\n",
      "\u001b[38;5;210m [7.988633800087811, 6.066459070814714]\n",
      "\u001b[38;5;189mIteration:  32\n",
      "\u001b[38;5;210m [7.973592678422495, 6.075824810952635]\n",
      "\u001b[38;5;189mIteration:  33\n",
      "\u001b[38;5;210m [7.95890042593742, 6.084087322143257]\n",
      "\u001b[38;5;189mIteration:  34\n",
      "\u001b[38;5;210m [7.944505338847474, 6.091204117043366]\n",
      "\u001b[38;5;189mIteration:  35\n",
      "\u001b[38;5;210m [7.930359287682022, 6.097142249229429]\n",
      "\u001b[38;5;189mIteration:  36\n",
      "\u001b[38;5;210m [7.916417856992136, 6.101878042700029]\n",
      "\u001b[38;5;189mIteration:  37\n",
      "\u001b[38;5;210m [7.902640421899046, 6.105396727013192]\n",
      "\u001b[38;5;189mIteration:  38\n",
      "\u001b[38;5;210m [7.888990165256688, 6.107691991135971]\n",
      "\u001b[38;5;189mIteration:  39\n",
      "\u001b[38;5;210m [7.875434040333966, 6.108765469531183]\n",
      "\u001b[38;5;189mIteration:  40\n",
      "\u001b[38;5;210m [7.861942684789938, 6.10862617410843]\n",
      "\u001b[38;5;189mIteration:  41\n",
      "\u001b[38;5;210m [7.848490292317915, 6.10728988544654]\n",
      "\u001b[38;5;189mIteration:  42\n",
      "\u001b[38;5;210m [7.835054448680299, 6.104778516180059]\n",
      "\u001b[38;5;189mIteration:  43\n",
      "\u001b[38;5;210m [7.8216159389624025, 6.101119458669223]\n",
      "\u001b[38;5;189mIteration:  44\n",
      "\u001b[38;5;210m [7.808158532765697, 6.096344928087198]\n",
      "\u001b[38;5;189mIteration:  45\n",
      "\u001b[38;5;210m [7.794668753769943, 6.090491310912146]\n",
      "\u001b[38;5;189mIteration:  46\n",
      "\u001b[38;5;210m [7.781135639655506, 6.083598527560421]\n",
      "\u001b[38;5;189mIteration:  47\n",
      "\u001b[38;5;210m [7.767550497827575, 6.075709416594281]\n",
      "\u001b[38;5;189mIteration:  48\n",
      "\u001b[38;5;210m [7.753906661759797, 6.066869146632017]\n",
      "\u001b[38;5;189mIteration:  49\n",
      "\u001b[38;5;210m [7.740199252108334, 6.057124660821761]\n",
      "\u001b[38;5;189mIteration:  50\n",
      "\u001b[38;5;210m [7.726424946068269, 6.046524157545415]\n",
      "\u001b[38;5;189mIteration:  51\n",
      "\u001b[38;5;210m [7.712581757776672, 6.035116609920468]\n",
      "\u001b[38;5;189mIteration:  52\n",
      "\u001b[38;5;210m [7.698668831930171, 6.022951325680763]\n",
      "\u001b[38;5;189mIteration:  53\n",
      "\u001b[38;5;210m [7.68468625219382, 6.010077548150814]\n",
      "\u001b[38;5;189mIteration:  54\n",
      "\u001b[38;5;210m [7.670634865442457, 5.996544098284762]\n",
      "\u001b[38;5;189mIteration:  55\n",
      "\u001b[38;5;210m [7.656516122401694, 5.982399057117333]\n",
      "\u001b[38;5;189mIteration:  56\n",
      "\u001b[38;5;210m [7.642331934845483, 5.967689487464692]\n",
      "\u001b[38;5;189mIteration:  57\n",
      "\u001b[38;5;210m [7.628084549160972, 5.952461193308465]\n",
      "\u001b[38;5;189mIteration:  58\n",
      "\u001b[38;5;210m [7.613776435806901, 5.936758514986944]\n",
      "\u001b[38;5;189mIteration:  59\n",
      "\u001b[38;5;210m [7.599410193965118, 5.920624158092103]\n",
      "\u001b[38;5;189mIteration:  60\n",
      "\u001b[38;5;210m [7.584988470511518, 5.904099053818849]\n",
      "\u001b[38;5;189mIteration:  61\n",
      "\u001b[38;5;210m [7.570513892307111, 5.887222248423082]\n",
      "\u001b[38;5;189mIteration:  62\n",
      "\u001b[38;5;210m [7.555989010726628, 5.870030819407477]\n",
      "\u001b[38;5;189mIteration:  63\n",
      "\u001b[38;5;210m [7.541416257295115, 5.852559816059507]\n",
      "\u001b[38;5;189mIteration:  64\n",
      "\u001b[38;5;210m [7.526797909287107, 5.834842222006337]\n",
      "\u001b[38;5;189mIteration:  65\n",
      "\u001b[38;5;210m [7.512136064152691, 5.816908937518964]\n",
      "\u001b[38;5;189mIteration:  66\n",
      "\u001b[38;5;210m [7.49743262166539, 5.79878877938676]\n",
      "\u001b[38;5;189mIteration:  67\n",
      "\u001b[38;5;210m [7.482689272733973, 5.7805084962878075]\n",
      "\u001b[38;5;189mIteration:  68\n",
      "\u001b[38;5;210m [7.467907493879818, 5.762092797695982]\n",
      "\u001b[38;5;189mIteration:  69\n",
      "\u001b[38;5;210m [7.453088546450203, 5.7435643944880095]\n",
      "\u001b[38;5;189mIteration:  70\n",
      "\u001b[38;5;210m [7.438233479712473, 5.724944049540401]\n",
      "\u001b[38;5;189mIteration:  71\n",
      "\u001b[38;5;210m [7.423343137052343, 5.706250636733788]\n",
      "\u001b[38;5;189mIteration:  72\n",
      "\u001b[38;5;210m [7.4084181645788405, 5.687501206909422]\n",
      "\u001b[38;5;189mIteration:  73\n",
      "\u001b[38;5;210m [7.393459021517435, 5.668711059447136]\n",
      "\u001b[38;5;189mIteration:  74\n",
      "\u001b[38;5;210m [7.3784659918496915, 5.649893818255181]\n",
      "\u001b[38;5;189mIteration:  75\n",
      "\u001b[38;5;210m [7.363439196731669, 5.631061511078598]\n",
      "\u001b[38;5;189mIteration:  76\n",
      "\u001b[38;5;210m [7.348378607292914, 5.6122246511437766]\n",
      "\u001b[38;5;189mIteration:  77\n",
      "\u001b[38;5;210m [7.33328405748301, 5.593392320261871]\n",
      "\u001b[38;5;189mIteration:  78\n",
      "\u001b[38;5;210m [7.318155256692524, 5.5745722526125405]\n",
      "\u001b[38;5;189mIteration:  79\n",
      "\u001b[38;5;210m [7.3029918019296955, 5.555770918521973]\n",
      "\u001b[38;5;189mIteration:  80\n",
      "\u001b[38;5;210m [7.287793189383269, 5.536993607634927]\n",
      "\u001b[38;5;189mIteration:  81\n",
      "\u001b[38;5;210m [7.272558825245212, 5.518244510960193]\n",
      "\u001b[38;5;189mIteration:  82\n",
      "\u001b[38;5;210m [7.257288035705349, 5.499526801341886]\n",
      "\u001b[38;5;189mIteration:  83\n",
      "\u001b[38;5;210m [7.241980076062624, 5.480842711976089]\n",
      "\u001b[38;5;189mIteration:  84\n",
      "\u001b[38;5;210m [7.2266341389258475, 5.462193612653458]\n",
      "\u001b[38;5;189mIteration:  85\n",
      "\u001b[38;5;210m [7.211249361500036, 5.443580083463779]\n",
      "\u001b[38;5;189mIteration:  86\n",
      "\u001b[38;5;210m [7.19582483197356, 5.42500198574868]\n",
      "\u001b[38;5;189mIteration:  87\n",
      "\u001b[38;5;210m [7.18035959503659, 5.40645853013361]\n",
      "\u001b[38;5;189mIteration:  88\n",
      "\u001b[38;5;210m [7.16485265657298, 5.387948341510651]\n",
      "\u001b[38;5;189mIteration:  89\n",
      "\u001b[38;5;210m [7.1493029875763865, 5.3694695208796395]\n",
      "\u001b[38;5;189mIteration:  90\n",
      "\u001b[38;5;210m [7.133709527347321, 5.351019703986939]\n",
      "\u001b[38;5;189mIteration:  91\n",
      "\u001b[38;5;210m [7.118071186031363, 5.332596116729447]\n",
      "\u001b[38;5;189mIteration:  92\n",
      "\u001b[38;5;210m [7.102386846560402, 5.314195627316157]\n",
      "\u001b[38;5;189mIteration:  93\n",
      "\u001b[38;5;210m [7.0866553660586105, 5.295814795201274]\n",
      "\u001b[38;5;189mIteration:  94\n",
      "\u001b[38;5;210m [7.070875576773497, 5.277449916821707]\n",
      "\u001b[38;5;189mIteration:  95\n",
      "\u001b[38;5;210m [7.055046286589905, 5.2590970681881375]\n",
      "\u001b[38;5;189mIteration:  96\n",
      "\u001b[38;5;210m [7.039166279181488, 5.240752144392787]\n",
      "\u001b[38;5;189mIteration:  97\n",
      "\u001b[38;5;210m [7.023234313850437, 5.222410896109077]\n",
      "\u001b[38;5;189mIteration:  98\n",
      "\u001b[38;5;210m [7.007249125101868, 5.204068963168409]\n",
      "\u001b[38;5;189mIteration:  99\n",
      "\u001b[38;5;210m [6.991209421994956, 5.1857219053078225]\n",
      "\u001b[38;5;189mIteration:  100\n",
      "\u001b[38;5;210m [6.975113887308299, 5.16736523018922]\n",
      "\u001b[38;5;189mIteration:  101\n",
      "\u001b[38;5;210m [6.95896117655257, 5.148994418796644]\n",
      "\u001b[38;5;189mIteration:  102\n",
      "\u001b[38;5;210m [6.9427499168592135, 5.130604948322481]\n",
      "\u001b[38;5;189mIteration:  103\n",
      "\u001b[38;5;210m [6.926478705769759, 5.112192312656979]\n",
      "\u001b[38;5;189mIteration:  104\n",
      "\u001b[38;5;210m [6.910146109946654, 5.093752040598011]\n",
      "\u001b[38;5;189mIteration:  105\n",
      "\u001b[38;5;210m [6.893750663822812, 5.075279711899601]\n",
      "\u001b[38;5;189mIteration:  106\n",
      "\u001b[38;5;210m [6.877290868204069, 5.056770971278753]\n",
      "\u001b[38;5;189mIteration:  107\n",
      "\u001b[38;5;210m [6.860765188835794, 5.038221540500261]\n",
      "\u001b[38;5;189mIteration:  108\n",
      "\u001b[38;5;210m [6.844172054942431, 5.019627228658862]\n",
      "\u001b[38;5;189mIteration:  109\n",
      "\u001b[38;5;210m [6.827509857746664, 5.000983940777139]\n",
      "\u001b[38;5;189mIteration:  110\n",
      "\u001b[38;5;210m [6.810776948972979, 4.982287684836149]\n",
      "\u001b[38;5;189mIteration:  111\n",
      "\u001b[38;5;210m [6.79397163933892, 4.963534577353894]\n",
      "\u001b[38;5;189mIteration:  112\n",
      "\u001b[38;5;210m [6.777092197036122, 4.944720847624486]\n",
      "\u001b[38;5;189mIteration:  113\n",
      "\u001b[38;5;210m [6.760136846202115, 4.925842840728166]\n",
      "\u001b[38;5;189mIteration:  114\n",
      "\u001b[38;5;210m [6.74310376538328, 4.906897019419487]\n",
      "\u001b[38;5;189mIteration:  115\n",
      "\u001b[38;5;210m [6.725991085988623, 4.887879964997673]\n",
      "\u001b[38;5;189mIteration:  116\n",
      "\u001b[38;5;210m [6.7087968907337885, 4.868788377259727]\n",
      "\u001b[38;5;189mIteration:  117\n",
      "\u001b[38;5;210m [6.691519212074389, 4.849619073633181]\n",
      "\u001b[38;5;189mIteration:  118\n",
      "\u001b[38;5;210m [6.674156030627702, 4.830368987581599]\n",
      "\u001b[38;5;189mIteration:  119\n",
      "\u001b[38;5;210m [6.6567052735817365, 4.811035166371857]\n",
      "\u001b[38;5;189mIteration:  120\n",
      "\u001b[38;5;210m [6.639164813090771, 4.791614768288309]\n",
      "\u001b[38;5;189mIteration:  121\n",
      "\u001b[38;5;210m [6.6215324646566085, 4.772105059374635]\n",
      "\u001b[38;5;189mIteration:  122\n",
      "\u001b[38;5;210m [6.603805985495017, 4.752503409780133]\n",
      "\u001b[38;5;189mIteration:  123\n",
      "\u001b[38;5;210m [6.585983072887007, 4.732807289782902]\n",
      "\u001b[38;5;189mIteration:  124\n",
      "\u001b[38;5;210m [6.568061362514975, 4.713014265558275]\n",
      "\u001b[38;5;189mIteration:  125\n",
      "\u001b[38;5;210m [6.550038426783883, 4.693121994756684]\n",
      "\u001b[38;5;189mIteration:  126\n",
      "\u001b[38;5;210m [6.531911773128128, 4.673128221951092]\n",
      "\u001b[38;5;189mIteration:  127\n",
      "\u001b[38;5;210m [6.513678842304885, 4.6530307740101575]\n",
      "\u001b[38;5;189mIteration:  128\n",
      "\u001b[38;5;210m [6.495337006675204, 4.632827555449458]\n",
      "\u001b[38;5;189mIteration:  129\n",
      "\u001b[38;5;210m [6.476883568474297, 4.612516543809378]\n",
      "\u001b[38;5;189mIteration:  130\n",
      "\u001b[38;5;210m [6.458315758072949, 4.59209578510471]\n",
      "\u001b[38;5;189mIteration:  131\n",
      "\u001b[38;5;210m [6.439630732232179, 4.571563389387641]\n",
      "\u001b[38;5;189mIteration:  132\n",
      "\u001b[38;5;210m [6.420825572353712, 4.550917526462591]\n",
      "\u001b[38;5;189mIteration:  133\n",
      "\u001b[38;5;210m [6.401897282729129, 4.53015642178837]\n",
      "\u001b[38;5;189mIteration:  134\n",
      "\u001b[38;5;210m [6.382842788790953, 4.509278352600349]\n",
      "\u001b[38;5;189mIteration:  135\n",
      "\u001b[38;5;210m [6.363658935369307, 4.4882816442827576]\n",
      "\u001b[38;5;189mIteration:  136\n",
      "\u001b[38;5;210m [6.344342484958147, 4.467164667018881]\n",
      "\u001b[38;5;189mIteration:  137\n",
      "\u001b[38;5;210m [6.3248901159955615, 4.445925832744853]\n",
      "\u001b[38;5;189mIteration:  138\n",
      "\u001b[38;5;210m [6.305298421163059, 4.424563592430826]\n",
      "\u001b[38;5;189mIteration:  139\n",
      "\u001b[38;5;210m [6.285563905709228, 4.403076433711758]\n",
      "\u001b[38;5;189mIteration:  140\n",
      "\u001b[38;5;210m [6.26568298580376, 4.381462878888582]\n",
      "\u001b[38;5;189mIteration:  141\n",
      "\u001b[38;5;210m [6.245651986928331, 4.359721483319479]\n",
      "\u001b[38;5;189mIteration:  142\n",
      "\u001b[38;5;210m [6.225467142311538, 4.3378508342200455]\n",
      "\u001b[38;5;189mIteration:  143\n",
      "\u001b[38;5;210m [6.205124591415723, 4.315849549890517]\n",
      "\u001b[38;5;189mIteration:  144\n",
      "\u001b[38;5;210m [6.184620378484307, 4.2937162793878345]\n",
      "\u001b[38;5;189mIteration:  145\n",
      "\u001b[38;5;210m [6.163950451159055, 4.271449702660169]\n",
      "\u001b[38;5;189mIteration:  146\n",
      "\u001b[38;5;210m [6.143110659177593, 4.249048531161578]\n",
      "\u001b[38;5;189mIteration:  147\n",
      "\u001b[38;5;210m [6.122096753162507, 4.226511508964911]\n",
      "\u001b[38;5;189mIteration:  148\n",
      "\u001b[38;5;210m [6.100904383514336, 4.20383741439145]\n",
      "\u001b[38;5;189mIteration:  149\n",
      "\u001b[38;5;210m [6.0795290994220395, 4.181025062176741]\n",
      "\u001b[38;5;189mIteration:  150\n",
      "\u001b[38;5;210m [6.057966348005648, 4.158073306192929]\n",
      "\u001b[38;5;189mIteration:  151\n",
      "\u001b[38;5;210m [6.0362114736072865, 4.134981042749261]\n",
      "\u001b[38;5;189mIteration:  152\n",
      "\u001b[38;5;210m [6.014259717248127, 4.111747214493776]\n",
      "\u001b[38;5;189mIteration:  153\n",
      "\u001b[38;5;210m [5.992106216270491, 4.08837081494086]\n",
      "\u001b[38;5;189mIteration:  154\n",
      "\u001b[38;5;210m [5.969746004185996, 4.064850893651263]\n",
      "\u001b[38;5;189mIteration:  155\n",
      "\u001b[38;5;210m [5.947174010752503, 4.0411865620930945]\n",
      "\u001b[38;5;189mIteration:  156\n",
      "\u001b[38;5;210m [5.924385062304619, 4.0173770002147045]\n",
      "\u001b[38;5;189mIteration:  157\n",
      "\u001b[38;5;210m [5.901373882364626, 3.9934214637625938]\n",
      "\u001b[38;5;189mIteration:  158\n",
      "\u001b[38;5;210m [5.878135092563007, 3.969319292380225]\n",
      "\u001b[38;5;189mIteration:  159\n",
      "\u001b[38;5;210m [5.854663213900231, 3.945069918526224]\n",
      "\u001b[38;5;189mIteration:  160\n",
      "\u001b[38;5;210m [5.830952668384005, 3.9206728772534083]\n",
      "\u001b[38;5;189mIteration:  161\n",
      "\u001b[38;5;210m [5.8069977810790965, 3.8961278168930282]\n",
      "\u001b[38;5;189mIteration:  162\n",
      "\u001b[38;5;210m [5.782792782609771, 3.871434510691726]\n",
      "\u001b[38;5;189mIteration:  163\n",
      "\u001b[38;5;210m [5.758331812158052, 3.8465928694518783]\n",
      "\u001b[38;5;189mIteration:  164\n",
      "\u001b[38;5;210m [5.733608921004479, 3.821602955229246]\n",
      "\u001b[38;5;189mIteration:  165\n",
      "\u001b[38;5;210m [5.708618076661545, 3.79646499614505]\n",
      "\u001b[38;5;189mIteration:  166\n",
      "\u001b[38;5;210m [5.683353167653814, 3.7711794023728467]\n",
      "\u001b[38;5;189mIteration:  167\n",
      "\u001b[38;5;210m [5.657808009002814, 3.7457467833637073]\n",
      "\u001b[38;5;189mIteration:  168\n",
      "\u001b[38;5;210m [5.631976348478903, 3.7201679663761795]\n",
      "\u001b[38;5;189mIteration:  169\n",
      "\u001b[38;5;210m [5.605851873686896, 3.694444016380357]\n",
      "\u001b[38;5;189mIteration:  170\n",
      "\u001b[38;5;210m [5.579428220056807, 3.6685762574078584]\n",
      "\u001b[38;5;189mIteration:  171\n",
      "\u001b[38;5;210m [5.552698979816046, 3.64256629542164]\n",
      "\u001b[38;5;189mIteration:  172\n",
      "\u001b[38;5;210m [5.5256577120243895, 3.6164160427812218]\n",
      "\u001b[38;5;189mIteration:  173\n",
      "\u001b[38;5;210m [5.498297953758452, 3.5901277443798314]\n",
      "\u001b[38;5;189mIteration:  174\n",
      "\u001b[38;5;210m [5.470613232537777, 3.5637040055302296]\n",
      "\u001b[38;5;189mIteration:  175\n",
      "\u001b[38;5;210m [5.442597080090291, 3.5371478216750956]\n",
      "\u001b[38;5;189mIteration:  176\n",
      "\u001b[38;5;210m [5.414243047560641, 3.5104626099959293]\n",
      "\u001b[38;5;189mIteration:  177\n",
      "\u001b[38;5;210m [5.385544722270739, 3.483652242990924]\n",
      "\u001b[38;5;189mIteration:  178\n",
      "\u001b[38;5;210m [5.3564957461477345, 3.4567210840871234]\n",
      "\u001b[38;5;189mIteration:  179\n",
      "\u001b[38;5;210m [5.327089835940433, 3.4296740253448514]\n",
      "\u001b[38;5;189mIteration:  180\n",
      "\u001b[38;5;210m [5.2973208053509815, 3.402516527302758]\n",
      "\u001b[38;5;189mIteration:  181\n",
      "\u001b[38;5;210m [5.267182589214158, 3.375254660999209]\n",
      "\u001b[38;5;189mIteration:  182\n",
      "\u001b[38;5;210m [5.2366692698618555, 3.347895152189728]\n",
      "\u001b[38;5;189mIteration:  183\n",
      "\u001b[38;5;210m [5.205775105815175, 3.3204454277603697]\n",
      "\u001b[38;5;189mIteration:  184\n",
      "\u001b[38;5;210m [5.174494562950781, 3.2929136643124095]\n",
      "\u001b[38;5;189mIteration:  185\n",
      "\u001b[38;5;210m [5.142822348291543, 3.2653088388639917]\n",
      "\u001b[38;5;189mIteration:  186\n",
      "\u001b[38;5;210m [5.11075344657399, 3.2376407815787878]\n",
      "\u001b[38;5;189mIteration:  187\n",
      "\u001b[38;5;210m [5.078283159746147, 3.209920230389029]\n",
      "\u001b[38;5;189mIteration:  188\n",
      "\u001b[38;5;210m [5.045407149548955, 3.1821588873301123]\n",
      "\u001b[38;5;189mIteration:  189\n",
      "\u001b[38;5;210m [5.012121483332039, 3.1543694763448675]\n",
      "\u001b[38;5;189mIteration:  190\n",
      "\u001b[38;5;210m [4.978422683249759, 3.1265658022469625]\n",
      "\u001b[38;5;189mIteration:  191\n",
      "\u001b[38;5;210m [4.944307778975957, 3.0987628104533425]\n",
      "\u001b[38;5;189mIteration:  192\n",
      "\u001b[38;5;210m [4.90977436406461, 3.070976647004402]\n",
      "\u001b[38;5;189mIteration:  193\n",
      "\u001b[38;5;210m [4.874820656068633, 3.043224718286451]\n",
      "\u001b[38;5;189mIteration:  194\n",
      "\u001b[38;5;210m [4.83944556050907, 3.015525749753288]\n",
      "\u001b[38;5;189mIteration:  195\n",
      "\u001b[38;5;210m [4.803648738761555, 2.9878998428114256]\n",
      "\u001b[38;5;189mIteration:  196\n",
      "\u001b[38;5;210m [4.7674306798949315, 2.960368528886344]\n",
      "\u001b[38;5;189mIteration:  197\n",
      "\u001b[38;5;210m [4.73079277645754, 2.9329548195248734]\n",
      "\u001b[38;5;189mIteration:  198\n",
      "\u001b[38;5;210m [4.69373740415878, 2.905683251211861]\n",
      "\u001b[38;5;189mIteration:  199\n",
      "\u001b[38;5;210m [4.656268005335884, 2.8785799233885694]\n",
      "\u001b[38;5;189mIteration:  200\n",
      "\u001b[38;5;210m [4.618389176027378, 2.8516725279578594]\n",
      "\u001b[38;5;189mIteration:  201\n",
      "\u001b[38;5;210m [4.580106756394003, 2.8249903683499165]\n",
      "\u001b[38;5;189mIteration:  202\n",
      "\u001b[38;5;210m [4.541427924133888, 2.798564366006372]\n",
      "\u001b[38;5;189mIteration:  203\n",
      "\u001b[38;5;210m [4.502361290430191, 2.7724270519261784]\n",
      "\u001b[38;5;189mIteration:  204\n",
      "\u001b[38;5;210m [4.4629169978452605, 2.746612540710903]\n",
      "\u001b[38;5;189mIteration:  205\n",
      "\u001b[38;5;210m [4.423106819434966, 2.721156484360352]\n",
      "\u001b[38;5;189mIteration:  206\n",
      "\u001b[38;5;210m [4.382944258199338, 2.69609600291334]\n",
      "\u001b[38;5;189mIteration:  207\n",
      "\u001b[38;5;210m [4.342444645811718, 2.6714695889178794]\n",
      "\u001b[38;5;189mIteration:  208\n",
      "\u001b[38;5;210m [4.301625239378303, 2.6473169826668372]\n",
      "\u001b[38;5;189mIteration:  209\n",
      "\u001b[38;5;210m [4.260505314775225, 2.6236790151686367]\n",
      "\u001b[38;5;189mIteration:  210\n",
      "\u001b[38;5;210m [4.219106254893814, 2.6005974159592635]\n",
      "\u001b[38;5;189mIteration:  211\n",
      "\u001b[38;5;210m [4.177451630900146, 2.5781145831241257]\n",
      "\u001b[38;5;189mIteration:  212\n",
      "\u001b[38;5;210m [4.135567274388268, 2.556273313309363]\n",
      "\u001b[38;5;189mIteration:  213\n",
      "\u001b[38;5;210m [4.093481338084617, 2.53511649008363]\n",
      "\u001b[38;5;189mIteration:  214\n",
      "\u001b[38;5;210m [4.051224342553969, 2.5146867297824365]\n",
      "\u001b[38;5;189mIteration:  215\n",
      "\u001b[38;5;210m [4.008829206175472, 2.495025984941355]\n",
      "\u001b[38;5;189mIteration:  216\n",
      "\u001b[38;5;210m [3.966331255515318, 2.4761751066082893]\n",
      "\u001b[38;5;189mIteration:  217\n",
      "\u001b[38;5;210m [3.923768213135374, 2.4581733682141884]\n",
      "\u001b[38;5;189mIteration:  218\n",
      "\u001b[38;5;210m [3.8811801598621174, 2.441057955258821]\n",
      "\u001b[38;5;189mIteration:  219\n",
      "\u001b[38;5;210m [3.8386094686158008, 2.4248634268005596]\n",
      "\u001b[38;5;189mIteration:  220\n",
      "\u001b[38;5;210m [3.796100707084299, 2.409621156576404]\n",
      "\u001b[38;5;189mIteration:  221\n",
      "\u001b[38;5;210m [3.7537005068372795, 2.3953587634522027]\n",
      "\u001b[38;5;189mIteration:  222\n",
      "\u001b[38;5;210m [3.7114573969292994, 2.382099542727574]\n",
      "\u001b[38;5;189mIteration:  223\n",
      "\u001b[38;5;210m [3.6694216006460003, 2.369861911494475]\n",
      "\u001b[38;5;189mIteration:  224\n",
      "\u001b[38;5;210m [3.627644794810976, 2.3586588826615382]\n",
      "\u001b[38;5;189mIteration:  225\n",
      "\u001b[38;5;210m [3.586179831988504, 2.348497583292288]\n",
      "\u001b[38;5;189mIteration:  226\n",
      "\u001b[38;5;210m [3.545080426976455, 2.3393788334524137]\n",
      "\u001b[38;5;189mIteration:  227\n",
      "\u001b[38;5;210m [3.5044008101590274, 2.3312968017199083]\n",
      "\u001b[38;5;189mIteration:  228\n",
      "\u001b[38;5;210m [3.464195351543752, 2.3242387528050115]\n",
      "\u001b[38;5;189mIteration:  229\n",
      "\u001b[38;5;210m [3.424518160591047, 2.31818490130831]\n",
      "\u001b[38;5;189mIteration:  230\n",
      "\u001b[38;5;210m [3.385422668195733, 2.3131083835064774]\n",
      "\u001b[38;5;189mIteration:  231\n",
      "\u001b[38;5;210m [3.346961198327268, 2.3089753562305786]\n",
      "\u001b[38;5;189mIteration:  232\n",
      "\u001b[38;5;210m [3.309184537801403, 2.305745228469144]\n",
      "\u001b[38;5;189mIteration:  233\n",
      "\u001b[38;5;210m [3.2721415133623264, 2.3033710274073282]\n",
      "\u001b[38;5;189mIteration:  234\n",
      "\u001b[38;5;210m [3.2358785856283783, 2.301799896359555]\n",
      "\u001b[38;5;189mIteration:  235\n",
      "\u001b[38;5;210m [3.2004394694347345, 2.300973717649076]\n",
      "\u001b[38;5;189mIteration:  236\n",
      "\u001b[38;5;210m [3.165864789651615, 2.300829849133184]\n",
      "\u001b[38;5;189mIteration:  237\n",
      "\u001b[38;5;210m [3.1321917806507504, 2.30130195897198]\n",
      "\u001b[38;5;189mIteration:  238\n",
      "\u001b[38;5;210m [3.099454036250757, 2.3023209395887685]\n",
      "\u001b[38;5;189mIteration:  239\n",
      "\u001b[38;5;210m [3.0676813152431333, 2.303815878751038]\n",
      "\u001b[38;5;189mIteration:  240\n",
      "\u001b[38;5;210m [3.036899405567106, 2.3057150634636265]\n",
      "\u001b[38;5;189mIteration:  241\n",
      "\u001b[38;5;210m [3.0071300479766636, 2.3079469910254984]\n",
      "\u001b[38;5;189mIteration:  242\n",
      "\u001b[38;5;210m [2.9783909177624617, 2.3104413612315335]\n",
      "\u001b[38;5;189mIteration:  243\n",
      "\u001b[38;5;210m [2.950695660903089, 2.313130024327131]\n",
      "\u001b[38;5;189mIteration:  244\n",
      "\u001b[38;5;210m [2.924053979072395, 2.3159478609245254]\n",
      "\u001b[38;5;189mIteration:  245\n",
      "\u001b[38;5;210m [2.8984717563553497, 2.3188335725948095]\n",
      "\u001b[38;5;189mIteration:  246\n",
      "\u001b[38;5;210m [2.873951219430394, 2.321730365143765]\n",
      "\u001b[38;5;189mIteration:  247\n",
      "\u001b[38;5;210m [2.8504911224280427, 2.3245865105065917]\n",
      "\u001b[38;5;189mIteration:  248\n",
      "\u001b[38;5;210m [2.828086947695197, 2.327355777569891]\n",
      "\u001b[38;5;189mIteration:  249\n",
      "\u001b[38;5;210m [2.8067311142543914, 2.3299977268395993]\n",
      "\u001b[38;5;189mIteration:  250\n",
      "\u001b[38;5;210m [2.7864131867748507, 2.3324778685037773]\n",
      "\u001b[38;5;189mIteration:  251\n",
      "\u001b[38;5;210m [2.767120079257543, 2.3347676878757215]\n",
      "\u001b[38;5;189mIteration:  252\n",
      "\u001b[38;5;210m [2.7488362492436638, 2.336844546249467]\n",
      "\u001b[38;5;189mIteration:  253\n",
      "\u001b[38;5;210m [2.731543880039163, 2.338691468690067]\n",
      "\u001b[38;5;189mIteration:  254\n",
      "\u001b[38;5;210m [2.715223050063987, 2.3402968330865397]\n",
      "\u001b[38;5;189mIteration:  255\n",
      "\u001b[38;5;210m [2.6998518898591732, 2.3416539768333977]\n",
      "\u001b[38;5;189mIteration:  256\n",
      "\u001b[38;5;210m [2.685406728421875, 2.342760738742281]\n",
      "\u001b[38;5;189mIteration:  257\n",
      "\u001b[38;5;210m [2.6718622313269487, 2.3436189542297488]\n",
      "\u001b[38;5;189mIteration:  258\n",
      "\u001b[38;5;210m [2.6591915335121965, 2.344233921535218]\n",
      "\u001b[38;5;189mIteration:  259\n",
      "\u001b[38;5;210m [2.6473663696664818, 2.3446138557832645]\n",
      "\u001b[38;5;189mIteration:  260\n",
      "\u001b[38;5;210m [2.636357204910817, 2.344769346232058]\n",
      "\u001b[38;5;189mIteration:  261\n",
      "\u001b[38;5;210m [2.6261333679697514, 2.3447128301753044]\n",
      "\u001b[38;5;189mIteration:  262\n",
      "\u001b[38;5;210m [2.616663188374792, 2.3444580948249736]\n",
      "\u001b[38;5;189mIteration:  263\n",
      "\u001b[38;5;210m [2.607914138507382, 2.344019816228644]\n",
      "\u001b[38;5;189mIteration:  264\n",
      "\u001b[38;5;210m [2.599852980554584, 2.3434131419890307]\n",
      "\u001b[38;5;189mIteration:  265\n",
      "\u001b[38;5;210m [2.5924459177834356, 2.3426533223573003]\n",
      "\u001b[38;5;189mIteration:  266\n",
      "\u001b[38;5;210m [2.5856587489886227, 2.341755392247218]\n",
      "\u001b[38;5;189mIteration:  267\n",
      "\u001b[38;5;210m [2.579457024564087, 2.3407339049222537]\n",
      "\u001b[38;5;189mIteration:  268\n",
      "\u001b[38;5;210m [2.5738062024034365, 2.339602716577601]\n",
      "\u001b[38;5;189mIteration:  269\n",
      "\u001b[38;5;210m [2.568671801741979, 2.3383748197878096]\n",
      "\u001b[38;5;189mIteration:  270\n",
      "\u001b[38;5;210m [2.564019553095764, 2.337062222814631]\n",
      "\u001b[38;5;189mIteration:  271\n",
      "\u001b[38;5;210m [2.5598155426030837, 2.335675871051224]\n",
      "\u001b[38;5;189mIteration:  272\n",
      "\u001b[38;5;210m [2.55602634929893, 2.3342256063908993]\n",
      "\u001b[38;5;189mIteration:  273\n",
      "\u001b[38;5;210m [2.552619174120074, 2.332720160018278]\n",
      "\u001b[38;5;189mIteration:  274\n",
      "\u001b[38;5;210m [2.5495619597180093, 2.331167173993908]\n",
      "\u001b[38;5;189mIteration:  275\n",
      "\u001b[38;5;210m [2.5468235004238857, 2.3295732470066017]\n",
      "\u001b[38;5;189mIteration:  276\n",
      "\u001b[38;5;210m [2.5443735419463174, 2.327943999771429]\n",
      "\u001b[38;5;189mIteration:  277\n",
      "\u001b[38;5;210m [2.5421828705783582, 2.3262841557303697]\n",
      "\u001b[38;5;189mIteration:  278\n",
      "\u001b[38;5;210m [2.540223391840587, 2.3245976329472557]\n",
      "\u001b[38;5;189mIteration:  279\n",
      "\u001b[38;5;210m [2.5384681985946917, 2.3228876433643837]\n",
      "\u001b[38;5;189mIteration:  280\n",
      "\u001b[38;5;210m [2.5368916287328456, 2.321156795894501]\n",
      "\u001b[38;5;189mIteration:  281\n",
      "\u001b[38;5;210m [2.535469312591448, 2.3194072001522077]\n",
      "\u001b[38;5;189mIteration:  282\n",
      "\u001b[38;5;210m [2.534178210263828, 2.3176405679783683]\n",
      "\u001b[38;5;189mIteration:  283\n",
      "\u001b[38;5;210m [2.5329966390054905, 2.3158583102765906]\n",
      "\u001b[38;5;189mIteration:  284\n",
      "\u001b[38;5;210m [2.5319042909459646, 2.3140616270588947]\n",
      "\u001b[38;5;189mIteration:  285\n",
      "\u001b[38;5;210m [2.530882241349854, 2.312251588984352]\n",
      "\u001b[38;5;189mIteration:  286\n",
      "\u001b[38;5;210m [2.529912947710675, 2.310429209065426]\n",
      "\u001b[38;5;189mIteration:  287\n",
      "\u001b[38;5;210m [2.528980240015163, 2.308595503605402]\n",
      "\u001b[38;5;189mIteration:  288\n",
      "\u001b[38;5;210m [2.5280693025827357, 2.306751541810368]\n",
      "\u001b[38;5;189mIteration:  289\n",
      "\u001b[38;5;210m [2.5271666479609145, 2.3048984838827353]\n",
      "\u001b[38;5;189mIteration:  290\n",
      "\u001b[38;5;210m [2.526260083438688, 2.303037607742455]\n",
      "\u001b[38;5;189mIteration:  291\n",
      "\u001b[38;5;210m [2.52533867082079, 2.3011703248297657]\n",
      "\u001b[38;5;189mIteration:  292\n",
      "\u001b[38;5;210m [2.5243926801808065, 2.2992981857121912]\n",
      "\u001b[38;5;189mIteration:  293\n",
      "\u001b[38;5;210m [2.523413538375482, 2.2974228764438918]\n",
      "\u001b[38;5;189mIteration:  294\n",
      "\u001b[38;5;210m [2.5223937731516233, 2.295546206803032]\n",
      "\u001b[38;5;189mIteration:  295\n",
      "\u001b[38;5;210m [2.521326953708074, 2.2936700916609802]\n",
      "\u001b[38;5;189mIteration:  296\n",
      "\u001b[38;5;210m [2.520207628586081, 2.2917965268157636]\n",
      "\u001b[38;5;189mIteration:  297\n",
      "\u001b[38;5;210m [2.5190312617517474, 2.289927560653145]\n",
      "\u001b[38;5;189mIteration:  298\n",
      "\u001b[38;5;210m [2.5177941677048694, 2.2880652629854494]\n",
      "\u001b[38;5;189mIteration:  299\n",
      "\u001b[38;5;210m [2.5164934464010846, 2.2862116923657183]\n",
      "\u001b[38;5;189mIteration:  300\n",
      "\u001b[38;5;210m [2.5151269187116214, 2.284368863088761]\n",
      "\u001b[38;5;189mIteration:  301\n",
      "\u001b[38;5;210m [2.513693063070442, 2.282538712977784]\n",
      "\u001b[38;5;189mIteration:  302\n",
      "\u001b[38;5;210m [2.5121909538754577, 2.2807230729222248]\n",
      "\u001b[38;5;189mIteration:  303\n",
      "\u001b[38;5;210m [2.5106202021228143, 2.2789236389859444]\n",
      "\u001b[38;5;189mIteration:  304\n",
      "\u001b[38;5;210m [2.5089808986639293, 2.2771419477512973]\n",
      "\u001b[38;5;189mIteration:  305\n",
      "\u001b[38;5;210m [2.507273560387505, 2.2753793554095716]\n",
      "\u001b[38;5;189mIteration:  306\n",
      "\u001b[38;5;210m [2.5054990795453618, 2.2736370209566674]\n",
      "\u001b[38;5;189mIteration:  307\n",
      "\u001b[38;5;210m [2.5036586763638033, 2.271915893708824]\n",
      "\u001b[38;5;189mIteration:  308\n",
      "\u001b[38;5;210m [2.5017538550126712, 2.270216705219674]\n",
      "\u001b[38;5;189mIteration:  309\n",
      "\u001b[38;5;210m [2.4997863629432553, 2.2685399655593037]\n",
      "\u001b[38;5;189mIteration:  310\n",
      "\u001b[38;5;210m [2.4977581535538795, 2.266885963809664]\n",
      "\u001b[38;5;189mIteration:  311\n",
      "\u001b[38;5;210m [2.4956713520984866, 2.265254772539396]\n",
      "\u001b[38;5;189mIteration:  312\n",
      "\u001b[38;5;210m [2.4935282247184207, 2.2636462559451136]\n",
      "\u001b[38;5;189mIteration:  313\n",
      "\u001b[38;5;210m [2.4913311504499904, 2.2620600812850817]\n",
      "\u001b[38;5;189mIteration:  314\n",
      "\u001b[38;5;210m [2.489082596040058, 2.2604957331845648]\n",
      "\u001b[38;5;189mIteration:  315\n",
      "\u001b[38;5;210m [2.48678509338725, 2.2589525303589455]\n",
      "\u001b[38;5;189mIteration:  316\n",
      "\u001b[38;5;210m [2.484441219417519, 2.2574296442802675]\n",
      "\u001b[38;5;189mIteration:  317\n",
      "\u001b[38;5;210m [2.4820535781979753, 2.255926119303927]\n",
      "\u001b[38;5;189mIteration:  318\n",
      "\u001b[38;5;210m [2.4796247850924105, 2.2544408937741145]\n",
      "\u001b[38;5;189mIteration:  319\n",
      "\u001b[38;5;210m [2.4771574527643403, 2.2529728216379024]\n",
      "\u001b[38;5;189mIteration:  320\n",
      "\u001b[38;5;210m [2.474654178838827, 2.2515206941180232]\n",
      "\u001b[38;5;189mIteration:  321\n",
      "\u001b[38;5;210m [2.472117535042072, 2.2500832610219996]\n",
      "\u001b[38;5;189mIteration:  322\n",
      "\u001b[38;5;210m [2.4695500576475338, 2.248659251299765]\n",
      "\u001b[38;5;189mIteration:  323\n",
      "\u001b[38;5;210m [2.46695423906883, 2.247247392501945]\n",
      "\u001b[38;5;189mIteration:  324\n",
      "\u001b[38;5;210m [2.464332520452689, 2.2458464288357503]\n",
      "\u001b[38;5;189mIteration:  325\n",
      "\u001b[38;5;210m [2.461687285139339, 2.244455137563802]\n",
      "\u001b[38;5;189mIteration:  326\n",
      "\u001b[38;5;210m [2.4590208528727735, 2.2430723435420785]\n",
      "\u001b[38;5;189mIteration:  327\n",
      "\u001b[38;5;210m [2.4563354746589208, 2.2416969317454316]\n",
      "\u001b[38;5;189mIteration:  328\n",
      "\u001b[38;5;210m [2.453633328185692, 2.2403278576816787]\n",
      "\u001b[38;5;189mIteration:  329\n",
      "\u001b[38;5;210m [2.450916513734506, 2.238964155646796]\n",
      "\u001b[38;5;189mIteration:  330\n",
      "\u001b[38;5;210m [2.4481870505283254, 2.237604944823468]\n",
      "\u001b[38;5;189mIteration:  331\n",
      "\u001b[38;5;210m [2.44544687347562, 2.2362494332717153]\n",
      "\u001b[38;5;189mIteration:  332\n",
      "\u001b[38;5;210m [2.442697830283101, 2.234896919903034]\n",
      "\u001b[38;5;189mIteration:  333\n",
      "\u001b[38;5;210m [2.4399416789218655, 2.2335467945671663]\n",
      "\u001b[38;5;189mIteration:  334\n",
      "\u001b[38;5;210m [2.4371800854419807, 2.2321985364130836]\n",
      "\u001b[38;5;189mIteration:  335\n",
      "\u001b[38;5;210m [2.4344146221386898, 2.2308517107120247]\n",
      "\u001b[38;5;189mIteration:  336\n",
      "\u001b[38;5;210m [2.4316467660799277, 2.2295059643505755]\n",
      "\u001b[38;5;189mIteration:  337\n",
      "\u001b[38;5;210m [2.4288778980091132, 2.22816102021547]\n",
      "\u001b[38;5;189mIteration:  338\n",
      "\u001b[38;5;210m [2.4261093016394835, 2.226816670699065]\n",
      "\u001b[38;5;189mIteration:  339\n",
      "\u001b[38;5;210m [2.4233421633567094, 2.2254727705557005]\n",
      "\u001b[38;5;189mIteration:  340\n",
      "\u001b[38;5;210m [2.4205775723451226, 2.2241292293345505]\n",
      "\u001b[38;5;189mIteration:  341\n",
      "\u001b[38;5;210m [2.4178165211500957, 2.2227860036049063]\n",
      "\u001b[38;5;189mIteration:  342\n",
      "\u001b[38;5;210m [2.41505990668487, 2.221443089175401]\n",
      "\u001b[38;5;189mIteration:  343\n",
      "\u001b[38;5;210m [2.4123085316850164, 2.220100513490612]\n",
      "\u001b[38;5;189mIteration:  344\n",
      "\u001b[38;5;210m [2.4095631066077443, 2.21875832836712]\n",
      "\u001b[38;5;189mIteration:  345\n",
      "\u001b[38;5;210m [2.406824251966953, 2.217416603207585]\n",
      "\u001b[38;5;189mIteration:  346\n",
      "\u001b[38;5;210m [2.4040925010883907, 2.216075418806361]\n",
      "\u001b[38;5;189mIteration:  347\n",
      "\u001b[38;5;210m [2.4013683032628967, 2.214734861834403]\n",
      "\u001b[38;5;189mIteration:  348\n",
      "\u001b[38;5;210m [2.3986520272694984, 2.213395020065477]\n",
      "\u001b[38;5;189mIteration:  349\n",
      "\u001b[38;5;210m [2.3959439652347188, 2.2120559783806697]\n",
      "\u001b[38;5;189mIteration:  350\n",
      "\u001b[38;5;210m [2.3932443367893765, 2.2107178155643603]\n",
      "\u001b[38;5;189mIteration:  351\n",
      "\u001b[38;5;210m [2.3905532934802225, 2.2093806018829016]\n",
      "\u001b[38;5;189mIteration:  352\n",
      "\u001b[38;5;210m [2.387870923390438, 2.2080443974174235]\n",
      "\u001b[38;5;189mIteration:  353\n",
      "\u001b[38;5;210m [2.385197255920925, 2.2067092511049737]\n",
      "\u001b[38;5;189mIteration:  354\n",
      "\u001b[38;5;210m [2.382532266682881, 2.2053752004276683]\n",
      "\u001b[38;5;189mIteration:  355\n",
      "\u001b[38;5;210m [2.379875882451998, 2.2040422716779906]\n",
      "\u001b[38;5;189mIteration:  356\n",
      "\u001b[38;5;210m [2.3772279861352037, 2.202710480719725]\n",
      "\u001b[38;5;189mIteration:  357\n",
      "\u001b[38;5;210m [2.3745884217023434, 2.201379834158303]\n",
      "\u001b[38;5;189mIteration:  358\n",
      "\u001b[38;5;210m [2.371956999037581, 2.2000503308314854]\n",
      "\u001b[38;5;189mIteration:  359\n",
      "\u001b[38;5;210m [2.369333498668284, 2.1987219635310993]\n",
      "\u001b[38;5;189mIteration:  360\n",
      "\u001b[38;5;210m [2.3667176763328204, 2.1973947208687816]\n",
      "\u001b[38;5;189mIteration:  361\n",
      "\u001b[38;5;210m [2.364109267352903, 2.1960685892031266]\n",
      "\u001b[38;5;189mIteration:  362\n",
      "\u001b[38;5;210m [2.3615079907805954, 2.1947435545519367]\n",
      "\u001b[38;5;189mIteration:  363\n",
      "\u001b[38;5;210m [2.3589135532950087, 2.19341960442119]\n",
      "\u001b[38;5;189mIteration:  364\n",
      "\u001b[38;5;210m [2.3563256528287124, 2.192096729491367]\n",
      "\u001b[38;5;189mIteration:  365\n",
      "\u001b[38;5;210m [2.3537439819089467, 2.190774925111828]\n",
      "\u001b[38;5;189mIteration:  366\n",
      "\u001b[38;5;210m [2.351168230703706, 2.189454192564378]\n",
      "\u001b[38;5;189mIteration:  367\n",
      "\u001b[38;5;210m [2.348598089767667, 2.1881345400678835]\n",
      "\u001b[38;5;189mIteration:  368\n",
      "\u001b[38;5;210m [2.3460332524875622, 2.1868159835063947]\n",
      "\u001b[38;5;189mIteration:  369\n",
      "\u001b[38;5;210m [2.3434734172307974, 2.185498546873399]\n",
      "\u001b[38;5;189mIteration:  370\n",
      "\u001b[38;5;210m [2.340918289205062, 2.1841822624343683]\n",
      "\u001b[38;5;189mIteration:  371\n",
      "\u001b[38;5;210m [2.3383675820401777, 2.1828671706185014]\n",
      "\u001b[38;5;189mIteration:  372\n",
      "\u001b[38;5;210m [2.3358210191061715, 2.1815533196580708]\n",
      "\u001b[38;5;189mIteration:  373\n",
      "\u001b[38;5;210m [2.3332783345842203, 2.180240765000358]\n",
      "\u001b[38;5;189mIteration:  374\n",
      "\u001b[38;5;210m [2.3307392743088355, 2.1789295685223204]\n",
      "\u001b[38;5;189mIteration:  375\n",
      "\u001b[38;5;210m [2.3282035964010106, 2.177619797581925]\n",
      "\u001b[38;5;189mIteration:  376\n",
      "\u001b[38;5;210m [2.3256710717130034, 2.17631152394283]\n",
      "\u001b[38;5;189mIteration:  377\n",
      "\u001b[38;5;210m [2.323141484105625, 2.175004822610171]\n",
      "\u001b[38;5;189mIteration:  378\n",
      "\u001b[38;5;210m [2.320614630578884, 2.1736997706154124]\n",
      "\u001b[38;5;189mIteration:  379\n",
      "\u001b[38;5;210m [2.3180903212762685, 2.17239644578708]\n",
      "\u001b[38;5;189mIteration:  380\n",
      "\u001b[38;5;210m [2.3155683793820674, 2.171094925542152]\n",
      "\u001b[38;5;189mIteration:  381\n",
      "\u001b[38;5;210m [2.3130486409299658, 2.169795285729915]\n",
      "\u001b[38;5;189mIteration:  382\n",
      "\u001b[38;5;210m [2.310530954539715, 2.168497599556487]\n",
      "\u001b[38;5;189mIteration:  383\n",
      "\u001b[38;5;210m [2.308015181097099, 2.1672019366139783]\n",
      "\u001b[38;5;189mIteration:  384\n",
      "\u001b[38;5;210m [2.305501193390626, 2.1659083620336808]\n",
      "\u001b[38;5;189mIteration:  385\n",
      "\u001b[38;5;210m [2.30298887571671, 2.164616935777896]\n",
      "\u001b[38;5;189mIteration:  386\n",
      "\u001b[38;5;210m [2.3004781234632063, 2.163327712080138]\n",
      "\u001b[38;5;189mIteration:  387\n",
      "\u001b[38;5;210m [2.2979688426794866, 2.162040739038647]\n",
      "\u001b[38;5;189mIteration:  388\n",
      "\u001b[38;5;210m [2.295460949639554, 2.1607560583636074]\n",
      "\u001b[38;5;189mIteration:  389\n",
      "\u001b[38;5;210m [2.292954370403108, 2.1594737052742015]\n",
      "\u001b[38;5;189mIteration:  390\n",
      "\u001b[38;5;210m [2.290449040378173, 2.158193708537831]\n",
      "\u001b[38;5;189mIteration:  391\n",
      "\u001b[38;5;210m [2.2879449038875306, 2.1569160906405163]\n",
      "\u001b[38;5;189mIteration:  392\n",
      "\u001b[38;5;210m [2.2854419137403092, 2.155640868074756]\n",
      "\u001b[38;5;189mIteration:  393\n",
      "\u001b[38;5;210m [2.282940030809074, 2.1543680517289525]\n",
      "\u001b[38;5;189mIteration:  394\n",
      "\u001b[38;5;210m [2.280439223612219, 2.153097647360978]\n",
      "\u001b[38;5;189mIteration:  395\n",
      "\u001b[38;5;210m [2.2779394679009037, 2.151829656137534]\n",
      "\u001b[38;5;189mIteration:  396\n",
      "\u001b[38;5;210m [2.2754407462495396, 2.15056407522062]\n",
      "\u001b[38;5;189mIteration:  397\n",
      "\u001b[38;5;210m [2.2729430476486483, 2.149300898382612]\n",
      "\u001b[38;5;189mIteration:  398\n",
      "\u001b[38;5;210m [2.2704463670989528, 2.1480401166322056]\n",
      "\u001b[38;5;189mIteration:  399\n",
      "\u001b[38;5;210m [2.2679507052057044, 2.146781718834618]\n",
      "\u001b[38;5;189mIteration:  400\n",
      "\u001b[38;5;210m [2.2654560677724622, 2.1455256923110304]\n",
      "\u001b[38;5;189mIteration:  401\n",
      "\u001b[38;5;210m [2.2629624653938865, 2.144272023404007]\n",
      "\u001b[38;5;189mIteration:  402\n",
      "\u001b[38;5;210m [2.2604699130474515, 2.1430206979977946]\n",
      "\u001b[38;5;189mIteration:  403\n",
      "\u001b[38;5;210m [2.2579784296844534, 2.1417717019845983]\n",
      "\u001b[38;5;189mIteration:  404\n",
      "\u001b[38;5;210m [2.255488037820982, 2.1405250216701583]\n",
      "\u001b[38;5;189mIteration:  405\n",
      "\u001b[38;5;210m [2.2529987631300896, 2.139280644114349]\n",
      "\u001b[38;5;189mIteration:  406\n",
      "\u001b[38;5;210m [2.2505106340366283, 2.1380385574046583]\n",
      "\u001b[38;5;189mIteration:  407\n",
      "\u001b[38;5;210m [2.248023681316613, 2.1367987508625332]\n",
      "\u001b[38;5;189mIteration:  408\n",
      "\u001b[38;5;210m [2.245537937703249, 2.1355612151845125]\n",
      "\u001b[38;5;189mIteration:  409\n",
      "\u001b[38;5;210m [2.2430534375019677, 2.1343259425217322]\n",
      "\u001b[38;5;189mIteration:  410\n",
      "\u001b[38;5;210m [2.240570216216869, 2.133092926502823]\n",
      "\u001b[38;5;189mIteration:  411\n",
      "\u001b[38;5;210m [2.2380883101911495, 2.131862162206443]\n",
      "\u001b[38;5;189mIteration:  412\n",
      "\u001b[38;5;210m [2.2356077562639673, 2.1306336460904776]\n",
      "\u001b[38;5;189mIteration:  413\n",
      "\u001b[38;5;210m [2.233128591446117, 2.129407375885613]\n",
      "\u001b[38;5;189mIteration:  414\n",
      "\u001b[38;5;210m [2.23065085261674, 2.1281833504612186]\n",
      "\u001b[38;5;189mIteration:  415\n",
      "\u001b[38;5;210m [2.2281745762430596, 2.1269615696715496]\n",
      "\u001b[38;5;189mIteration:  416\n",
      "\u001b[38;5;210m [2.225699798124775, 2.1257420341900533]\n",
      "\u001b[38;5;189mIteration:  417\n",
      "\u001b[38;5;210m [2.2232265531645488, 2.124524745339104]\n",
      "\u001b[38;5;189mIteration:  418\n",
      "\u001b[38;5;210m [2.220754875165474, 2.123309704921905]\n",
      "\u001b[38;5;189mIteration:  419\n",
      "\u001b[38;5;210m [2.2182847966562065, 2.1220969150624787]\n",
      "\u001b[38;5;189mIteration:  420\n",
      "\u001b[38;5;210m [2.215816348743915, 2.120886378058787]\n",
      "\u001b[38;5;189mIteration:  421\n",
      "\u001b[38;5;210m [2.2133495609948555, 2.1196780962530606]\n",
      "\u001b[38;5;189mIteration:  422\n",
      "\u001b[38;5;210m [2.2108844613420224, 2.1184720719223624]\n",
      "\u001b[38;5;189mIteration:  423\n",
      "\u001b[38;5;210m [2.208421076018899, 2.117268307191462]\n",
      "\u001b[38;5;189mIteration:  424\n",
      "\u001b[38;5;210m [2.205959429518081, 2.11606680396901]\n",
      "\u001b[38;5;189mIteration:  425\n",
      "\u001b[38;5;210m [2.2034995445731984, 2.1148675639071586]\n",
      "\u001b[38;5;189mIteration:  426\n",
      "\u001b[38;5;210m [2.201041442162346, 2.1136705883838594]\n",
      "\u001b[38;5;189mIteration:  427\n",
      "\u001b[38;5;210m [2.198585141531006, 2.112475878506332]\n",
      "\u001b[38;5;189mIteration:  428\n",
      "\u001b[38;5;210m [2.196130660232389, 2.1112834351336205]\n",
      "\u001b[38;5;189mIteration:  429\n",
      "\u001b[38;5;210m [2.1936780141828347, 2.1100932589155312]\n",
      "\u001b[38;5;189mIteration:  430\n",
      "\u001b[38;5;210m [2.191227217730138, 2.108905350345018]\n",
      "\u001b[38;5;189mIteration:  431\n",
      "\u001b[38;5;210m [2.1887782837324035, 2.107719709820739]\n",
      "\u001b[38;5;189mIteration:  432\n",
      "\u001b[38;5;210m [2.186331223645296, 2.1065363377164754]\n",
      "\u001b[38;5;189mIteration:  433\n",
      "\u001b[38;5;210m [2.183886047615481, 2.105355234454075]\n",
      "\u001b[38;5;189mIteration:  434\n",
      "\u001b[38;5;210m [2.1814427645782968, 2.10417640057677]\n",
      "\u001b[38;5;189mIteration:  435\n",
      "\u001b[38;5;210m [2.17900138235779, 2.102999836819897]\n",
      "\u001b[38;5;189mIteration:  436\n",
      "\u001b[38;5;210m [2.176561907767448, 2.101825544176436]\n",
      "\u001b[38;5;189mIteration:  437\n",
      "\u001b[38;5;210m [2.174124346710153, 2.100653523955085]\n",
      "\u001b[38;5;189mIteration:  438\n",
      "\u001b[38;5;210m [2.171688704276074, 2.099483777829086]\n",
      "\u001b[38;5;189mIteration:  439\n",
      "\u001b[38;5;210m [2.169254984837468, 2.09831630787445]\n",
      "\u001b[38;5;189mIteration:  440\n",
      "\u001b[38;5;210m [2.166823192139543, 2.0971511165967107]\n",
      "\u001b[38;5;189mIteration:  441\n",
      "\u001b[38;5;210m [2.164393329386683, 2.095988206945758]\n",
      "\u001b[38;5;189mIteration:  442\n",
      "\u001b[38;5;210m [2.161965399323667, 2.0948275823188314]\n",
      "\u001b[38;5;189mIteration:  443\n",
      "\u001b[38;5;210m [2.1595394043115297, 2.0936692465520834]\n",
      "\u001b[38;5;189mIteration:  444\n",
      "\u001b[38;5;210m [2.1571153463979758, 2.092513203901513]\n",
      "\u001b[38;5;189mIteration:  445\n",
      "\u001b[38;5;210m [2.154693227382357, 2.091359459014399]\n",
      "\u001b[38;5;189mIteration:  446\n",
      "\u001b[38;5;210m [2.152273048875306, 2.090208016892568]\n",
      "\u001b[38;5;189mIteration:  447\n",
      "\u001b[38;5;210m [2.149854812353307, 2.0890588828490704]\n",
      "\u001b[38;5;189mIteration:  448\n",
      "\u001b[38;5;210m [2.147438519208428, 2.087912062459885]\n",
      "\u001b[38;5;189mIteration:  449\n",
      "\u001b[38;5;210m [2.145024170793543, 2.086767561512377]\n",
      "\u001b[38;5;189mIteration:  450\n",
      "\u001b[38;5;210m [2.1426117684634645, 2.08562538595223]\n",
      "\u001b[38;5;189mIteration:  451\n",
      "\u001b[38;5;210m [2.140201313612241, 2.0844855418304338]\n",
      "\u001b[38;5;189mIteration:  452\n",
      "\u001b[38;5;210m [2.137792807707114, 2.0833480352519036]\n",
      "\u001b[38;5;189mIteration:  453\n",
      "\u001b[38;5;210m [2.135386252319289, 2.0822128723270157]\n",
      "\u001b[38;5;189mIteration:  454\n",
      "\u001b[38;5;210m [2.1329816491520064, 2.0810800591272973]\n",
      "\u001b[38;5;189mIteration:  455\n",
      "\u001b[38;5;210m [2.1305790000660183, 2.079949601646159]\n",
      "\u001b[38;5;189mIteration:  456\n",
      "\u001b[38;5;210m [2.1281783071027913, 2.0788215057654043]\n",
      "\u001b[38;5;189mIteration:  457\n",
      "\u001b[38;5;210m [2.125779572505537, 2.0776957772279943]\n",
      "\u001b[38;5;189mIteration:  458\n",
      "\u001b[38;5;210m [2.123382798738245, 2.0765724216172945]\n",
      "\u001b[38;5;189mIteration:  459\n",
      "\u001b[38;5;210m [2.1209879885027543, 2.0754514443428373]\n",
      "\u001b[38;5;189mIteration:  460\n",
      "\u001b[38;5;210m [2.1185951447539426, 2.0743328506323766]\n",
      "\u001b[38;5;189mIteration:  461\n",
      "\u001b[38;5;210m [2.116204270713029, 2.073216645529876]\n",
      "\u001b[38;5;189mIteration:  462\n",
      "\u001b[38;5;210m [2.1138153698789526, 2.0721028338988896]\n",
      "\u001b[38;5;189mIteration:  463\n",
      "\u001b[38;5;210m [2.1114284460378587, 2.0709914204306807]\n",
      "\u001b[38;5;189mIteration:  464\n",
      "\u001b[38;5;210m [2.109043503270561, 2.0698824096562998]\n",
      "\u001b[38;5;189mIteration:  465\n",
      "\u001b[38;5;210m [2.1066605459580177, 2.0687758059618253]\n",
      "\u001b[38;5;189mIteration:  466\n",
      "\u001b[38;5;210m [2.1042795787847166, 2.0676716136059152]\n",
      "\u001b[38;5;189mIteration:  467\n",
      "\u001b[38;5;210m [2.1019006067400103, 2.0665698367388425]\n",
      "\u001b[38;5;189mIteration:  468\n",
      "\u001b[38;5;210m [2.099523635117314, 2.065470479422189]\n",
      "\u001b[38;5;189mIteration:  469\n",
      "\u001b[38;5;210m [2.0971486695112462, 2.064373545648456]\n",
      "\u001b[38;5;189mIteration:  470\n",
      "\u001b[38;5;210m [2.094775715812718, 2.063279039359928]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m     adam(t, [nn1, nn2], num_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [nn1, nn2]\n\u001b[1;32m---> 11\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPSI_0\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[194], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(init_conditions)\u001b[0m\n\u001b[0;32m      5\u001b[0m nn1 \u001b[38;5;241m=\u001b[39m NeuralNetwork(init_conditions[\u001b[38;5;241m0\u001b[39m], derivative, \u001b[38;5;241m1\u001b[39m, hidden_sizes, \u001b[38;5;241m1\u001b[39m, activation_fns)\n\u001b[0;32m      6\u001b[0m nn2 \u001b[38;5;241m=\u001b[39m NeuralNetwork(init_conditions[\u001b[38;5;241m1\u001b[39m], derivative, \u001b[38;5;241m1\u001b[39m, hidden_sizes, \u001b[38;5;241m1\u001b[39m, activation_fns)\n\u001b[1;32m----> 7\u001b[0m \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [nn1, nn2]\n",
      "Cell \u001b[1;32mIn[193], line 41\u001b[0m, in \u001b[0;36madam\u001b[1;34m(t, neural_networks, num_iters, step_size, b1, b2, eps)\u001b[0m\n\u001b[0;32m     38\u001b[0m prev_loss \u001b[38;5;241m=\u001b[39m print_loss(t, neural_networks, weights_list, i, prev_loss)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(neural_networks)):\n\u001b[1;32m---> 41\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[43mloss_grad_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneural_networks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(neural_networks[j]\u001b[38;5;241m.\u001b[39mweights)):\n\u001b[0;32m     44\u001b[0m         m[j][k] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m b1) \u001b[38;5;241m*\u001b[39m g[j][k]      \u001b[38;5;241m+\u001b[39m b1 \u001b[38;5;241m*\u001b[39m m[j][k]  \u001b[38;5;66;03m# First  moment estimate.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\differential_operators.py:28\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad\u001b[39m(fun, x):\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    Returns a function which computes the gradient of `fun` with respect to\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    positional argument number `argnum`. The returned function takes the same\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    arguments as `fun`, but returns the gradient instead. The function `fun`\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    should be scalar-valued. The gradient has the same type as the argument.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[0;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[1;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(start_node, fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[1;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[125], line 23\u001b[0m, in \u001b[0;36melementwise_loss_function\u001b[1;34m(t, neural_networks, weights_list, index)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melementwise_loss_function\u001b[39m(t: np\u001b[38;5;241m.\u001b[39marray, neural_networks: List[NeuralNetwork], weights_list, index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmse_loss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneural_networks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_list\u001b[49m\u001b[43m)\u001b[49m[index]\n",
      "Cell \u001b[1;32mIn[125], line 12\u001b[0m, in \u001b[0;36mmse_loss_function\u001b[1;34m(t, neural_networks, weights_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the mean squared error a list of neural network.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    Mean squared error value\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(neural_networks)\n\u001b[1;32m---> 12\u001b[0m trial_sol \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mneural_networks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(neural_networks))])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(neural_networks)):\n\u001b[0;32m     15\u001b[0m     grad_star \u001b[38;5;241m=\u001b[39m neural_networks[i]\u001b[38;5;241m.\u001b[39mderivative(t, trial_sol)\n",
      "Cell \u001b[1;32mIn[124], line 77\u001b[0m, in \u001b[0;36mNeuralNetwork.trial_solution\u001b[1;34m(self, t, weights)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrial_solution\u001b[39m(\u001b[38;5;28mself\u001b[39m, t: np\u001b[38;5;241m.\u001b[39marray, weights: List[np\u001b[38;5;241m.\u001b[39marray]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the trial solution of the system of ODEs.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m        dimension (len(t),)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(t\u001b[38;5;241m.\u001b[39msize)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_condition \u001b[38;5;241m+\u001b[39m t \u001b[38;5;241m*\u001b[39m fp\n",
      "Cell \u001b[1;32mIn[124], line 62\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, t, weights)\u001b[0m\n\u001b[0;32m     60\u001b[0m a \u001b[38;5;241m=\u001b[39m t\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers):\n\u001b[1;32m---> 62\u001b[0m     z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(weights[i], \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     63\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fns[i](z)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\numpy\\numpy_wrapper.py:38\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(arr_list, axis)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;129m@primitive\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_args\u001b[39m(axis, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _np\u001b[38;5;241m.\u001b[39mconcatenate(args, axis)\u001b[38;5;241m.\u001b[39mview(ndarray)\n\u001b[1;32m---> 38\u001b[0m concatenate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m arr_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m : \u001b[43mconcatenate_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marr_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m vstack \u001b[38;5;241m=\u001b[39m row_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m tup: concatenate([atleast_2d(_m) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m tup], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhstack\u001b[39m(tup):\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\numpy\\numpy_wrapper.py:37\u001b[0m, in \u001b[0;36mconcatenate_args\u001b[1;34m(axis, *args)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;129m@primitive\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_args\u001b[39m(axis, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(ndarray)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(init_conditions):\n",
    "    t = np.arange(0, 3, 0.3)\n",
    "    hidden_sizes = np.array([10])\n",
    "    activation_fns = [sigmoid] * (len(hidden_sizes)) + [lambda x: x]\n",
    "    nn1 = NeuralNetwork(init_conditions[0], derivative, 1, hidden_sizes, 1, activation_fns)\n",
    "    nn2 = NeuralNetwork(init_conditions[1], derivative, 1, hidden_sizes, 1, activation_fns)\n",
    "    adam(t, [nn1, nn2], num_iters=100000, step_size=0.001)\n",
    "\n",
    "    return [nn1, nn2]\n",
    "\n",
    "nns = train(PSI_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ode(neural_network: NeuralNetwork, scale=1, dt=0.3):\n",
    "   t = np.arange(0, 3, dt)\n",
    "   res = neural_network.trial_solution(t, neural_network.weights)\n",
    "   fig = plt.figure(figsize=(5, 5))\n",
    "   ax = fig.add_subplot()\n",
    "   ax.plot(res[0], res[1], lw=1)\n",
    "   ax.plot(analytical_solution(t)[0], analytical_solution(t)[1], lw=1)\n",
    "   plt.legend(['nn', 'analytical'])\n",
    "\n",
    "   print(analytical_solution(t) - res[0])\n",
    "\n",
    "def plot_system_ode(neural_networks: List[NeuralNetwork], scale=1, dt=0.3):\n",
    "   t = np.arange(0, 3, dt)\n",
    "   res = [neural_networks[i].trial_solution(t, neural_networks[i].weights) for i in range(len(neural_networks))]\n",
    "   fig = plt.figure(figsize=(5, 5))\n",
    "   ax = fig.add_subplot()\n",
    "   ax.plot(res[0], res[1], lw=1)\n",
    "   ax.plot(analytical_solution(t)[0], analytical_solution(t)[1], lw=1)\n",
    "   plt.legend(['nn', 'analytical'])\n",
    "\n",
    "def simulate_sode(t, initial_conditions, derivative) -> Tuple[np.ndarray, np.ndarray]:\n",
    "   \"\"\"Simulate the system of ODEs over the time interval [0, dt * num_steps].\n",
    "\n",
    "   Args:\n",
    "      dt: The t step\n",
    "      initial_conditions: The initial conditions\n",
    "      num_steps: The number of t steps to calculate\n",
    "   \n",
    "   Returns:\n",
    "      A tuple of two NumPy arrays: the function output values, and the derivatives.\n",
    "   \"\"\"\n",
    "   df_dt = np.empty((len(t), len(initial_conditions)))\n",
    "   output = np.empty((len(t), len(initial_conditions)))\n",
    "   output[0] = initial_conditions\n",
    "\n",
    "   for i in range(len(t) - 1):\n",
    "      dt = t[i + 1] - t[i]\n",
    "      output[i + 1] = output[i] + derivative(t[i], output[i]) * dt\n",
    "      df_dt[i] = derivative(t[i], output[i])\n",
    "   \n",
    "   return output, df_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"darkgrid\", palette=\"muted\", font='DeJavu Serif')\n",
    "plot_system_ode(nns)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
