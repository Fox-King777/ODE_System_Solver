{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorentz System\n",
    "\n",
    "$\\frac{\\mathrm{d}x}{\\mathrm{d}t} = \\sigma (y - x), \\\\[6pt]$\n",
    "\n",
    "\n",
    "$\\frac{\\mathrm{d}y}{\\mathrm{d}t} = x (\\rho - z) - y, \\\\[6pt]$\n",
    "\n",
    "\n",
    "$\\frac{\\mathrm{d}z}{\\mathrm{d}t} = x y - \\beta z.$\n",
    "\n",
    "$σ = 10$, $β = 8/3$ and $ρ = 28$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, elementwise_grad\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z) -> float:\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def tanh(z) -> float:\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "\n",
    "def elu(z, alpha: float) -> float:\n",
    "    return alpha * (np.exp(z) - 1) if z < 0 else z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Solution & Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_solution(\n",
    "    input: np.array, parameters: list, initial_conditions: np.array\n",
    ") -> np.array:\n",
    "    print(\"flag 1\")\n",
    "    print(initial_conditions)\n",
    "    print(input)\n",
    "    print(forward_propogation(input, parameters))\n",
    "    print(input * forward_propogation(input, parameters))\n",
    "    return initial_conditions + input * forward_propogation(input, parameters)\n",
    "\n",
    "\n",
    "def right_hand_side(\n",
    "    input: np.array, trial_sol: np.array, constants: np.array\n",
    ") -> np.array:\n",
    "    return np.array(\n",
    "        [\n",
    "            constants[0] * (trial_sol[1] - trial_sol[0]),\n",
    "            trial_sol[0] * (constants[2] - trial_sol[2]) - trial_sol[1],\n",
    "            trial_sol[0] * trial_sol[1] - constants[1] * trial_sol[2],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def lorenz(xyz, *, s=10, r=28, b=2.667):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz : array-like, shape (3,)\n",
    "       Point of interest in three-dimensional space.\n",
    "    s, r, b : float\n",
    "       Parameters defining the Lorenz attractor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xyz_dot : array, shape (3,)\n",
    "       Values of the Lorenz attractor's partial derivatives at *xyz*.\n",
    "    \"\"\"\n",
    "    x, y, z = xyz\n",
    "    x_dot = s * (y - x)\n",
    "    y_dot = r * x - y - x * z\n",
    "    z_dot = x * y - b * z\n",
    "    return np.array([x_dot, y_dot, z_dot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss_function(\n",
    "    input, parameters: list, constants: np.array, initial_conditions: np.array\n",
    "):\n",
    "    print(\"flag 0\")\n",
    "    trial_sol = trial_solution(input, parameters, initial_conditions)\n",
    "    print(\"flag 2\")\n",
    "    prediction = right_hand_side(input, trial_sol, constants)\n",
    "    neural_network_gradient = elementwise_grad(trial_solution, 0)(\n",
    "        input, parameters, initial_conditions\n",
    "    )\n",
    "\n",
    "\n",
    "    error_squared = (neural_network_gradient - prediction) ** 2\n",
    "\n",
    "    loss_sum = np.sum(error_squared)\n",
    "\n",
    "\n",
    "    return loss_sum / np.shape(error_squared)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(input_size: int, hidden_sizes: np.array, output_size: int):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # hidden weights and biases\n",
    "    hidden_weights = [np.random.randn(hidden_sizes[0], input_size)]\n",
    "    for i in range(1, hidden_sizes.shape[0]):\n",
    "        hidden_weights.append(np.random.randn(hidden_sizes[i], hidden_sizes[i - 1]))\n",
    "\n",
    "    hidden_biases = [np.zeros((h, 1)) for h in hidden_sizes]\n",
    "\n",
    "    # output weights and biases\n",
    "    output_weights = np.random.randn(output_size, hidden_sizes[-1])\n",
    "    output_bias = np.zeros((output_size, 1))\n",
    "\n",
    "    parameters = [hidden_weights, hidden_biases, output_weights, output_bias]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propogation(input: np.array, parameters: list):\n",
    "    hidden_weights, hidden_biases, output_weights, output_bias = parameters\n",
    "    num_hidden_layers = len(hidden_weights)\n",
    "\n",
    "    # hidden layers\n",
    "    z = np.matmul(hidden_weights[0], input) + hidden_biases[0]\n",
    "    a = sigmoid(z)\n",
    "    for i in range(1, num_hidden_layers):\n",
    "        z = np.matmul(hidden_weights[i], a) + hidden_biases[i]\n",
    "        a = sigmoid(z)\n",
    "\n",
    "    # output layer\n",
    "    z = np.matmul(output_weights, a) + output_bias\n",
    "    a = sigmoid(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = init_parameters(1, np.array([2, 3, 4]), 3)\n",
    "len(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(\n",
    "    input: np.array,\n",
    "    parameters: list,\n",
    "    constants: np.array,\n",
    "    initial_conditions: np.array,\n",
    "    num_iter: int,\n",
    "    learn_rate: float,\n",
    "):\n",
    "    loss_grad_function = grad(MSE_loss_function, 1)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        loss_grad = loss_grad_function(input, parameters, constants, initial_conditions)\n",
    "        return loss_grad.shape\n",
    "        # hidden layers\n",
    "        for j in range(len(parameters[0])):\n",
    "            parameters[j] = parameters[j] - learn_rate * loss_grad[j]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag 0\n",
      "flag 1\n",
      "[0 0 0]\n",
      "[1]\n",
      "Autograd ArrayBox with value [[0.39456145 0.39020071]\n",
      " [0.49644285 0.49879528]\n",
      " [0.9190612  0.91674261]]\n",
      "Autograd ArrayBox with value [[0.39456145 0.39020071]\n",
      " [0.49644285 0.49879528]\n",
      " [0.9190612  0.91674261]]\n",
      "Autograd ArrayBox with value [[0.39456145 0.39020071]\n",
      " [0.49644285 0.49879528]\n",
      " [0.9190612  0.91674261]]\n",
      "Autograd ArrayBox with value [[0.39456145 0.39020071]\n",
      " [0.49644285 0.49879528]\n",
      " [0.9190612  0.91674261]]\n",
      "Autograd ArrayBox with value [[0.39456145 0.39020071]\n",
      " [0.49644285 0.49879528]\n",
      " [0.9190612  0.91674261]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mback_propogation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[126], line 12\u001b[0m, in \u001b[0;36mback_propogation\u001b[1;34m(input, parameters, constants, initial_conditions, num_iter, learn_rate)\u001b[0m\n\u001b[0;32m      9\u001b[0m loss_grad_function \u001b[38;5;241m=\u001b[39m grad(MSE_loss_function, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iter):\n\u001b[1;32m---> 12\u001b[0m     loss_grad \u001b[38;5;241m=\u001b[39m \u001b[43mloss_grad_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_conditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_grad\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# hidden layers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\differential_operators.py:28\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad\u001b[39m(fun, x):\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    Returns a function which computes the gradient of `fun` with respect to\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    positional argument number `argnum`. The returned function takes the same\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    arguments as `fun`, but returns the gradient instead. The function `fun`\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    should be scalar-valued. The gradient has the same type as the argument.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[0;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[1;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(start_node, fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[1;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[115], line 5\u001b[0m, in \u001b[0;36mMSE_loss_function\u001b[1;34m(input, parameters, constants, initial_conditions)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mMSE_loss_function\u001b[39m(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28minput\u001b[39m, parameters: \u001b[38;5;28mlist\u001b[39m, constants: np\u001b[38;5;241m.\u001b[39marray, initial_conditions: np\u001b[38;5;241m.\u001b[39marray\n\u001b[0;32m      3\u001b[0m ):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflag 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     trial_sol \u001b[38;5;241m=\u001b[39m \u001b[43mtrial_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_conditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflag 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m right_hand_side(\u001b[38;5;28minput\u001b[39m, trial_sol, constants)\n",
      "Cell \u001b[1;32mIn[114], line 9\u001b[0m, in \u001b[0;36mtrial_solution\u001b[1;34m(input, parameters, initial_conditions)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(forward_propogation(\u001b[38;5;28minput\u001b[39m, parameters))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m forward_propogation(\u001b[38;5;28minput\u001b[39m, parameters))\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minitial_conditions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforward_propogation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\numpy\\numpy_boxes.py:34\u001b[0m, in \u001b[0;36mArrayBox.__radd__\u001b[1;34m(self, other)\u001b[0m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__radd__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\tracer.py:44\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m parents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(box\u001b[38;5;241m.\u001b[39m_node \u001b[38;5;28;01mfor\u001b[39;00m _     , box \u001b[38;5;129;01min\u001b[39;00m boxed_args)\n\u001b[0;32m     43\u001b[0m argnums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(argnum    \u001b[38;5;28;01mfor\u001b[39;00m argnum, _   \u001b[38;5;129;01min\u001b[39;00m boxed_args)\n\u001b[1;32m---> 44\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mf_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m node \u001b[38;5;241m=\u001b[39m node_constructor(ans, f_wrapped, argvals, kwargs, argnums, parents)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n",
      "File \u001b[1;32mc:\\Users\\zheyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autograd\\tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (3,2) "
     ]
    }
   ],
   "source": [
    "back_propogation(\n",
    "    np.array([1]), parameters, np.array([1, 1, 1]), np.array([0, 0, 0]), 1, 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
