{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorentz System\n",
    "\n",
    "$\\frac{\\mathrm{d}x}{\\mathrm{d}t} = \\sigma (y - x), \\\\[6pt]$\n",
    "\n",
    "\n",
    "$\\frac{\\mathrm{d}y}{\\mathrm{d}t} = x (\\rho - z) - y, \\\\[6pt]$\n",
    "\n",
    "\n",
    "$\\frac{\\mathrm{d}z}{\\mathrm{d}t} = x y - \\beta z.$\n",
    "\n",
    "$σ = 10$, $β = 8/3$ and $ρ = 28$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, elementwise_grad\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def tanh(z):\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "\n",
    "def elu(z, alpha: float):\n",
    "    return alpha * (np.exp(z) - 1) if z < 0 else z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Solution & Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_solution(\n",
    "    input: np.array, parameters: list, initial_conditions: np.array\n",
    ") -> np.array:\n",
    "    return np.linspace(\n",
    "        initial_conditions, initial_conditions, input.size\n",
    "    ).T + input * forward_propogation(input, parameters)\n",
    "\n",
    "\n",
    "def right_hand_side(\n",
    "    input: np.array, trial_sol: np.array, constants: np.array\n",
    ") -> np.array:\n",
    "    return np.array(\n",
    "        [\n",
    "            constants[0] * (trial_sol[1] - trial_sol[0]),\n",
    "            trial_sol[0] * (constants[2] - trial_sol[2]) - trial_sol[1],\n",
    "            trial_sol[0] * trial_sol[1] - constants[1] * trial_sol[2],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def lorenz(xyz, *, s=10, r=28, b=2.667):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz : array-like, shape (3,)\n",
    "       Point of interest in three-dimensional space.\n",
    "    s, r, b : float\n",
    "       Parameters defining the Lorenz attractor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xyz_dot : array, shape (3,)\n",
    "       Values of the Lorenz attractor's partial derivatives at *xyz*.\n",
    "    \"\"\"\n",
    "    x, y, z = xyz\n",
    "    x_dot = s * (y - x)\n",
    "    y_dot = r * x - y - x * z\n",
    "    z_dot = x * y - b * z\n",
    "    return np.array([x_dot, y_dot, z_dot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss_function(\n",
    "    input, parameters: list, constants: np.array, initial_conditions: np.array\n",
    "):\n",
    "    trial_sol = trial_solution(input, parameters, initial_conditions)\n",
    "    prediction = right_hand_side(input, trial_sol, constants)\n",
    "    neural_network_gradient = elementwise_grad(trial_solution, 0)(\n",
    "        input, parameters, initial_conditions\n",
    "    )\n",
    "\n",
    "    error_squared = (neural_network_gradient - prediction) ** 2\n",
    "\n",
    "    loss_sum = np.sum(error_squared)\n",
    "\n",
    "    return loss_sum / np.shape(error_squared)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(input_size: int, hidden_sizes: np.array, output_size: int):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # hidden weights and biases\n",
    "    hidden_weights = [np.random.randn(hidden_sizes[0], input_size)]\n",
    "    for i in range(1, hidden_sizes.shape[0]):\n",
    "        hidden_weights.append(np.random.randn(hidden_sizes[i], hidden_sizes[i - 1]))\n",
    "\n",
    "    hidden_biases = [np.zeros((h, 1)) for h in hidden_sizes]\n",
    "\n",
    "    # output weights and biases\n",
    "    output_weights = np.random.randn(output_size, hidden_sizes[-1])\n",
    "    output_bias = np.zeros((output_size, 1))\n",
    "\n",
    "    parameters = [hidden_weights, hidden_biases, output_weights, output_bias]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propogation(input: np.array, parameters: list):\n",
    "    hidden_weights, hidden_biases, output_weights, output_bias = parameters\n",
    "    num_hidden_layers = len(hidden_weights)\n",
    "\n",
    "    # hidden layers\n",
    "    z = np.matmul(hidden_weights[0], input) + hidden_biases[0]\n",
    "    a = sigmoid(z)\n",
    "    for i in range(1, num_hidden_layers):\n",
    "        z = np.matmul(hidden_weights[i], a) + hidden_biases[i]\n",
    "        a = sigmoid(z)\n",
    "\n",
    "    # output layer\n",
    "    z = np.matmul(output_weights, a) + output_bias\n",
    "    a = sigmoid(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.55298982  0.6536186   0.8644362  -0.74216502]\n",
      " [ 2.26975462 -1.45436567  0.04575852 -0.18718385]\n",
      " [ 1.53277921  1.46935877  0.15494743  0.37816252]]\n"
     ]
    }
   ],
   "source": [
    "parameters = init_parameters(1, np.array([2, 3, 4]), 3)\n",
    "print(parameters[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(\n",
    "    input: np.array,\n",
    "    parameters: list,\n",
    "    constants: np.array,\n",
    "    initial_conditions: np.array,\n",
    "    num_iter: int,\n",
    "    learn_rate: float,\n",
    "):\n",
    "    loss_grad_function = grad(MSE_loss_function, 1)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        loss_grad = loss_grad_function(input, parameters, constants, initial_conditions)\n",
    "        # hidden layers\n",
    "        for j in range(len(parameters)):\n",
    "            for k in range(len(parameters[j])):\n",
    "                parameters[j][k] = parameters[j][k] - learn_rate * loss_grad[j][k]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[ 1.76405235],\n",
      "       [ 0.40015721],\n",
      "       [ 0.97873798],\n",
      "       [ 2.2408932 ],\n",
      "       [ 1.86755799],\n",
      "       [-0.97727788],\n",
      "       [ 0.95008842],\n",
      "       [-0.15135721],\n",
      "       [-0.10321885],\n",
      "       [ 0.4105985 ]])], [array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])], array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323,\n",
      "         0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
      "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462,\n",
      "        -1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877],\n",
      "       [ 0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215,\n",
      "         0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.]])]\n",
      "[[array([[nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan]])], [array([[nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan]])], array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]), array([[nan],\n",
      "       [nan],\n",
      "       [nan]])]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "t = np.arange(0, 10, 0.01)\n",
    "t = np.reshape(t, (1, 1000))\n",
    "\n",
    "\n",
    "\n",
    "constants = np.array([10.0, 8 / 3, 28.0])\n",
    "initial_conditions = np.array([0.0, 1.0, 1.05])\n",
    "num_iter = 5\n",
    "learn_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "parameters = init_parameters(1, np.array([10]), 3)\n",
    "print(parameters)\n",
    "parameters = back_propogation(\n",
    "    t, parameters, constants, initial_conditions, num_iter, learn_rate\n",
    ")\n",
    "print(parameters)\n",
    "\n",
    "\n",
    "res = trial_solution(t, parameters, initial_conditions)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 1.  , 1.  , 1.05, 1.05])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(initial_conditions, 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [1.  , 1.  , 1.  , ..., 1.  , 1.  , 1.  ],\n",
       "       [1.05, 1.05, 1.05, ..., 1.05, 1.05, 1.05]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(initial_conditions, initial_conditions, 1000).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
